现有工作主要考虑目标域是静态的情况
然而，现实场景中，目标域分布可能会随着时间的推移而变化
本文提出了一种持续测试时适应方法（CoTTA），其由两部分组成
1、通过使用权重平均和增强平均预测来减少误差累积
2、为避免灾难性遗忘，在每次迭代期间将一小部分神经元随机恢复到源预训练权重，以帮助长期保留源知识

当目标测试数据源自不断变化的环境时，自训练方法可能变得不稳定，原因可归结为两个方面：
1、由于分布变化，伪标签变得更加嘈杂和错误校准
2、由于模型长期不断适应新的分布，源域的知识更难保存，导致灾难性遗忘

本文的目的：从现成的源预训练模型开始，不断使其适应当前的测试数据
![image.png](https://papernote-1394983352.cos.ap-nanjing.myqcloud.com/tta-note-img/20260119151702142.png)

本文假设目标测试数据流来自不断变化的环境。预测和更新在线执行，模型只能访问当前的数据流，而无法访问完整的测试数据或任何源数据。这一设置非常符合现实世界的机器感知系统，例如自动驾驶系统应对不断变化的周围环境（晴天 $\longrightarrow$ 阴天 $\longrightarrow$ 雨天）


CoTTA 解决了现有方法的两个局限性，两个组成部分：
- 旨在减轻误差累计。通过两种方式提升自训练框架下的伪标签质量：
	- 使用权重平均教师模型来提供更准确的预测，因为<font color="#de7802">平均教师预测通常比标准模型具有更高的质量</font>
	- 对于域差距较大的测试数据，使用增强平均（augmentation-averaged）预测来进一步提高伪标签的质量
- 旨在保护源知识并避免遗忘：将网络中的一小部分神经元随机恢复到预先训练的源模型

![image.png](https://papernote-1394983352.cos.ap-nanjing.myqcloud.com/tta-note-img/20260119162206486.png)

##### 加权平均伪标签
使用加权平均教师模型 $f_{\theta'}$ 来生成伪标签
在时间步 $t = 0$，教师模型由源预训练网络初始化
在时间步 $t$，首先由教师模型生成伪标签 $\hat{y'}_t^T = f_{\theta_t^{'}}(x_t^T)$，学生模型 $f_{\theta_t}$ 通过交叉熵损失进行更新
![image.png](https://papernote-1394983352.cos.ap-nanjing.myqcloud.com/tta-note-img/20260119164658307.png)

更新完学生模型后，通过指数移动平均更新教师模型的权重

加权平均一致性（weight-averaged consistency）的好处：
- 加权平均预测更为准确，在持续适应过程中受到误差累积的影响较小
- 教师模型的预测对过去迭代中模型的信息进行编码，在长期持续适应中不太可能遭受灾难性遗忘

##### 增强平均伪标签
考虑测试时的域偏移并通过预测置信度来近似域差距。仅当域差距较大时才应用增强，以减少误差累积
具体来说，域差距通过预训练源模型的预测置信度来衡量：较低的置信度表示较大的域差距，相对较高的置信度表示较小的域差距
- 置信度较高且大于阈值时，使用教师模型的直接预测标签作为伪标签，而不使用任何增强
- 置信度较低时，额外应用 N 个随机增强来进一步提高伪标签质量

![image.png](https://papernote-1394983352.cos.ap-nanjing.myqcloud.com/tta-note-img/20260119173709268.png)

##### 随机复原
为了进一步解决灾难性遗忘问题，提出了一种随机恢复方法，该方法显式地从源预训练模型中恢复知识
这可以看作是 Dropout 的一种特殊形式，通过将可训练权重中的少量张量元素随机恢复到初始权重，网络可以避免偏离初始源模型太远，从而避免灾难性遗忘

![image.png](https://papernote-1394983352.cos.ap-nanjing.myqcloud.com/tta-note-img/20260119192921516.png)
