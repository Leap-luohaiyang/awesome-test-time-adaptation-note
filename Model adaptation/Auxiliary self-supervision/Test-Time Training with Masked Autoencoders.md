在训练阶段，TTT 同时优化主任务和自监督任务
在测试阶段，对于每个测试输入，仅通过自监督任务调整模型，然后在主任务上做出预测

自监督任务的选择至关重要：
1、必须足够通用，以便在广泛的潜在测试分布上为主任务产生有用的特征
2、不能太简单或太难，否则测试输入将无法提供有用的信号

什么样的一个任务才是难度合适的通用任务？
本文聚焦于自然图像共享的基本性质：空间光滑（spatial smoothness）性，即 $xy$ 空间中信息的局部冗余性。通俗来说，作者认为图像与文本不同，其存在大量的冗余信息，仅需要图像的一小部分就可以提取到合适的语义信息，因此可以根据小部分的图像重建获取到原始图像（掩码自编码器的基本思路）

当训练和测试分布不同时，如果无法访问遵循测试分布的数据，泛化本质上就是困难的
在一种分布偏移（例如高斯噪声）上通过训练或微调获得的鲁棒性通常不会转移到另一种分布偏移（例如椒盐噪声）上

TTT 通过自监督为每个测试样本生成不同的模型

采用旋转预测作为自监督借口任务的缺陷：普遍性有限，往往要么太容易要么太难
对于自然的户外场景，仅通过检测地平线方向就可以了，无需进一步了解场景，这样的旋转预测就太容易了
对于自上而下视图的图片，旋转预测又太难了，因为从每个方向看起来都同样合理

本文使用 MAE 代替论文 [[Test-Time Training with Self-Supervision for Generalization under Distribution Shifts]] 中的自监督部分

**架构**：$Y$ 形，特征提取器 $f$ 同时接一个自监督头 $g$ 和一个主任务头 $h$。$f$ 为 MAE 的编码器，$g$ 为其解码器，均为 ViT 架构。对于主任务头 $h$，MAE 的原始论文使用从编码器特征维度到类别数量的线性映射。本文的作者认为用线性层实现 $h$ 只是一种传统的技术惯例，并将其替换为 ViT-Base 以使其更具表现力

**训练设置**：本文所采用的 MAE 模型以 ViT-Large 作为编码器，并且该编码器在 ImageNet-1k 上以重构为任务进行了预训练。将编码器与未经训练的主任务头结合起来有三种方式：fine-tuning、probing 和 joint training
1）Fine-tuning：训练时，以端到端方式训练 $h \circ f$ （同时更新 $h$ 和 $f$ 的权重），$f$ 被驱动去专门化于识别任务，丢弃与识别无关的信息（这些信息可能对重建很重要）。此时，分类头 $h$ 学会依赖这些高度特化的识别特征；测试时，TTT 会通过重建任务更新 $f$，从而强行将 $f$ 拉向重建任务的解空间。这将导致 $f$ 的特征表示发生漂移，不再是 $h$ 所依赖的那种“纯识别特征”
2）ViT probing：仅训练 $h$，冻结 $f$
3）joint training：[[Test-Time Training with Self-Supervision for Generalization under Distribution Shifts]] 当中用的就是这种方式，通过将主任务损失和辅助任务的损失相加，联合训练 $h \circ f$ 和 $g \circ f$。然而使用 MAE 时，这种结合方式在验证集上的表现不佳

**Training-time training**：利用预训练的 MAE 的编码器 $f_0$，通过交叉熵损失来训练主任务头，训练好的主任务头表示为 $h_0$

**Test-time training**：在测试时，在 ViT probing 得到的 $h_0$，以及经过预训练的 MAE 的编码器 $f_0$ 和解码器 $g_0$ 的基础上，当测试输入 $x$ 到达时，通过优化 MAE 中的像素级重构 MSE 损失得到 $f_x$ 和 $g_x$，在完成对 $x$ 的预测后，丢弃 $f_x$ 和 $g_x$ 并将权重重置为 $f_0$ 和 $g_0$ 以用于下一个测试输入



